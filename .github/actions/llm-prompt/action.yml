name: 'LLM Prompt Action'
description: 'Calls StackSpot LLM API with OAuth authentication'
author: 'Your Name'

inputs:
  tenant:
    description: 'StackSpot tenant identifier'
    required: true
  client_id:
    description: 'OAuth client ID'
    required: true
  client_secret:
    description: 'OAuth client secret'
    required: true
  conversation_id:
    description: 'Conversation identifier'
    required: true
  agent_id:
    description: 'Agent identifier'
    required: true
  user_prompt:
    description: 'User prompt for the LLM'
    required: true

outputs:
  response:
    description: 'LLM response text'
    value: ${{ steps.llm.outputs.response }}

runs:
  using: 'composite'
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        set -euo pipefail
        
        # Store inputs in temporary files to avoid shell escaping issues
        echo '${{ toJSON(inputs.tenant) }}' | jq -r '.' > /tmp/tenant
        echo '${{ toJSON(inputs.client_id) }}' | jq -r '.' > /tmp/client_id
        echo '${{ toJSON(inputs.client_secret) }}' | jq -r '.' > /tmp/client_secret
        echo '${{ toJSON(inputs.conversation_id) }}' | jq -r '.' > /tmp/conversation_id
        echo '${{ toJSON(inputs.agent_id) }}' | jq -r '.' > /tmp/agent_id
        echo '${{ toJSON(inputs.user_prompt) }}' | jq -r '.' > /tmp/user_prompt
        
        # Set environment variables from files
        echo "TENANT=$(cat /tmp/tenant)" >> $GITHUB_ENV
        echo "CLIENT_ID=$(cat /tmp/client_id)" >> $GITHUB_ENV
        echo "CLIENT_SECRET=$(cat /tmp/client_secret)" >> $GITHUB_ENV
        echo "CONVERSATION_ID=$(cat /tmp/conversation_id)" >> $GITHUB_ENV
        echo "AGENT_ID=$(cat /tmp/agent_id)" >> $GITHUB_ENV
        echo "USER_PROMPT<<EOF" >> $GITHUB_ENV
        cat /tmp/user_prompt >> $GITHUB_ENV
        echo "EOF" >> $GITHUB_ENV
        
        # Mask sensitive data
        echo "::add-mask::$(cat /tmp/client_secret)"
        
        # Cleanup temporary files
        rm -f /tmp/tenant /tmp/client_id /tmp/client_secret /tmp/conversation_id /tmp/agent_id /tmp/user_prompt
        
        # Validate required inputs
        if [[ -z "$TENANT" || -z "$CLIENT_ID" || -z "$CLIENT_SECRET" || -z "$CONVERSATION_ID" || -z "$AGENT_ID" || -z "$USER_PROMPT" ]]; then
          echo "Error: All required inputs must be provided"
          exit 1
        fi

    - name: Get OAuth Token
      id: oauth
      shell: bash
      run: |
        set -euo pipefail
        
        echo "Requesting OAuth token..."
        response=$(curl --fail --silent --location \
          --request POST "https://idm.stackspot.com/${TENANT}/oidc/oauth/token" \
          --header 'Content-Type: application/x-www-form-urlencoded' \
          --data-urlencode "client_id=${CLIENT_ID}" \
          --data-urlencode 'grant_type=client_credentials' \
          --data-urlencode "client_secret=${CLIENT_SECRET}")
        
        if ! token=$(echo "$response" | jq -r '.access_token // empty'); then
          echo "Error: Failed to parse access token from response"
          echo "Response: $response"
          exit 1
        fi
        
        if [[ -z "$token" || "$token" == "null" ]]; then
          echo "Error: No access token received"
          echo "Response: $response"
          exit 1
        fi
        
        echo "::add-mask::$token"
        echo "token=$token" >> $GITHUB_OUTPUT

    - name: Call LLM API and Set Output
      id: llm
      shell: bash
      run: |
        set -euo pipefail
        
        echo "Calling LLM API..."
        
        # Create the JSON payload using environment variables
        payload=$(jq -nc \
          --arg conversation_id "$CONVERSATION_ID" \
          --arg agent_id "$AGENT_ID" \
          --arg user_prompt "$USER_PROMPT" \
          '{
            "context": {
              "conversation_id": $conversation_id,
              "upload_ids": [],
              "agent_id": $agent_id,
              "agent_built_in": true,
              "os": "github-action",
              "platform": "github-action",
              "platform_version": "1.0",
              "stackspot_ai_version": "2.4.0"
            },
            "user_prompt": $user_prompt
          }')
        
        echo "Making API request..."
        
        # Make the API call with timeout and better error handling
        timeout 300 curl --fail --silent --show-error \
          'https://genai-code-buddy-api.stackspot.com/v3/chat' \
          -H "accept: text/event-stream" \
          -H "authorization: Bearer ${{ steps.oauth.outputs.token }}" \
          -H "content-type: application/json" \
          --data-raw "$payload" \
          > stream_response.txt || {
            echo "Error: API call failed"
            if [[ -f stream_response.txt ]]; then
              echo "Stream response content:"
              cat stream_response.txt
            fi
            exit 1
          }
        
        echo "Processing stream response..."
        
        # Process the stream response
        final_response=""
        while IFS= read -r line; do
          if [[ "$line" =~ ^data:\ (.+)$ ]]; then
            data_content="${BASH_REMATCH[1]}"
            if [[ -n "$data_content" && "$data_content" != "{}" ]]; then
              answer=$(echo "$data_content" | jq -r 'select(.answer != null) | .answer' 2>/dev/null || echo "")
              if [[ -n "$answer" ]]; then
                final_response="${final_response}${answer}"
              fi
            fi
          fi
        done < stream_response.txt
        
        # Cleanup
        rm -f stream_response.txt
        
        if [[ -z "$final_response" ]]; then
          echo "Warning: No response content received from LLM"
        fi
        
        echo "Response length: ${#final_response} characters"
        
        # Set output using proper multiline format
        delimiter="LLMRESPONSE_$(date +%s)_$$"
        {
          echo "response<<${delimiter}"
          echo "$final_response"
          echo "$delimiter"
        } >> $GITHUB_OUTPUT